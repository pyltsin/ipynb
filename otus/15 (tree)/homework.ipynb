{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Весь код, который нужно разобрать, будем дебажить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[3,2],[4,4],[2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([[1], [2], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = x.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сортируем внутри строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[4, 4],\n",
       "         [3, 2]],\n",
       " \n",
       "        [[3, 2],\n",
       "         [4, 4]],\n",
       " \n",
       "        [[3, 2],\n",
       "         [4, 4]]]), array([[[2],\n",
       "         [1]],\n",
       " \n",
       "        [[1],\n",
       "         [2]],\n",
       " \n",
       "        [[1],\n",
       "         [2]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_x, sorted_y = x[sorted_idx], y[sorted_idx]\n",
    "sorted_x, sorted_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пока непонятно что, скорее всего передаем ОДИН признак. Попробуем еще раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([7, 6, 5,4,3,2,1,0])\n",
    "y=np.array([1, 1, 1,1,0,0,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 5, 4, 3, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = x.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([2, 2, 0, 0, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_x, sorted_y = x[sorted_idx], y[sorted_idx]\n",
    "sorted_x, sorted_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсортировали значения по возрастанию признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_number = np.unique(y).shape[0]\n",
    "class_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили количество уникальный классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_sorted_y = sorted_y\n",
    "splitted_sorted_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удалил лишнее обрезание, так как это должно выполняться в другом методе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_sorted_y = sorted_y\n",
    "r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (1)\n",
    "\n",
    "r_border_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получили список, где будем делить (правые границы изменения классов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если класс по размеру не разделим, то возвращаем float('+inf'), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "one_hot_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодируем классы - количество строк - количество возможных делений, количество колоннок - количество классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_el_count = r_border_ids - np.append([0], r_border_ids[:-1])\n",
    "eq_el_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "количество одинаковых элементов (после отсечения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(r_border_ids.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получаем индексы для всех строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_y[r_border_ids - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получаем значения левых границ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "классы должны быть закодированы, начиная с 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "one_hot_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_el_count.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "class_increments        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(sorted_y[:], minlength=class_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_increments[0] = class_increments[0] \n",
    "class_increments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили количество классов КРОМЕ находящиегося справа на ВСЕЙ выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [2., 0., 2.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "l_class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "наконец-то получили количество классов слева при разделении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 4., 0.],\n",
       "       [0., 4., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_class_count = np.bincount(y) - l_class_count\n",
    "r_class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получили количество классов справа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "l_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сумма классов слева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_sizes = sorted_y.shape[0] - l_sizes\n",
    "r_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сумма классов справа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С кодом разобрались. Теперь тестируем критерии информативности.\n",
    "Так как берется левая и правая часть и берется минимум, то просто берем сумму левой и правой части по информативности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def gini(l_c, l_s, r_c, r_s):\n",
    "        #l_class_count, l_sizes, r_class_count, r_sizes\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        \n",
    "        sum_l = np.sum(np.power(l_c, 2), axis=1)\n",
    "        c_l = np.power(l_s.reshape([1, l_s.shape[0]*l_s.shape[1]])[0], 2)\n",
    "        \n",
    "        sum_r = np.sum(np.power(r_c, 2), axis=1)\n",
    "        c_r = np.power(r_s.reshape([1, r_s.shape[0]*r_s.shape[1]])[0], 2)\n",
    "        return 2 - sum_l/c_l - sum_r/c_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44444444, 0.5       ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(l_class_count, l_sizes, r_class_count, r_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 2.],\n",
       "        [2., 0., 2.]]), array([[2],\n",
       "        [4]], dtype=int64), array([[2., 4., 0.],\n",
       "        [0., 4., 0.]]), array([[6],\n",
       "        [4]], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_class_count, l_sizes, r_class_count, r_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4444444444444444, 0.5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-4/4+1-4/36-16/36, 1-8/16+1-16/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совпало. Идем дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 1. ],\n",
       "       [0.5, 0. , 0.5]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_class_count/l_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(l_c, l_s, r_c, r_s):\n",
    "    p_l = l_c/l_s\n",
    "    p_r = r_c/r_s\n",
    "    p_ll = np.log2(p_l, where = p_l!=0)\n",
    "    p_rl = np.log2(p_r,  where = p_r!=0)\n",
    "    return - np.sum(p_l*p_ll, axis=1) - np.sum(p_r*p_rl, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91829583, 1.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(l_class_count, l_sizes, r_class_count, r_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclass(l_c, l_s, r_c, r_s):\n",
    "    p_l = l_c/l_s\n",
    "    p_r = r_c/r_s\n",
    "    m_l = np.max(p_l, axis=1)\n",
    "    m_r = np.max(p_r, axis=1)\n",
    "    return 2 - m_l - m_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.5       ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass(l_class_count, l_sizes, r_class_count, r_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь определения индексов feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_ids_sqrt(n_feature):\n",
    "    feature_ids = np.arange(n_feature)\n",
    "    np.random.shuffle(feature_ids)\n",
    "    return feature_ids[:int(n_feature**0.5)]\n",
    "        \n",
    "def get_feature_ids_log2(n_feature):\n",
    "    feature_ids = np.arange(n_feature)\n",
    "    np.random.shuffle(feature_ids)\n",
    "    return feature_ids[:int(math.log2(n_feature))]\n",
    "\n",
    "def get_feature_ids_N(n_feature):\n",
    "    return np.arange(n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_ids_sqrt(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 5, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_ids_log2(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_ids_N(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "все кажется нормально"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть r_border_id и y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_border_ids = np.array([1,3,4,5,6])\n",
    "splitted_sorted_y = np.array([0,1,1,2,1,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая строчка нужна, так как вычисляем длину для y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_el_count = r_border_ids - np.append([0], r_border_ids[:-1])\n",
    "eq_el_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_code[np.arange(r_border_ids.shape[0]), splitted_sorted_y[r_border_ids - 1]] = eq_el_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 2., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, type_node = None, feature_id = None, threshold = None, clazz = None, proba = None):\n",
    "            self.type_node = type_node\n",
    "            self.feature_id = feature_id,\n",
    "            self.threshold = threshold\n",
    "            self.proba = proba\n",
    "            \n",
    "            self.__left = None\n",
    "            self.__right = None\n",
    "        \n",
    "        def createLeft(self):\n",
    "            self.__left = MyDecisionTreeClassifier.Node()\n",
    "            return self.__left\n",
    "        \n",
    "        def createRight(self):\n",
    "            self.__right = MyDecisionTreeClassifier.Node()\n",
    "            return self.__right\n",
    "        \n",
    "        def getLeft(self):\n",
    "            return self.__left\n",
    "        \n",
    "        def getRight(self):\n",
    "            return self.__right\n",
    "        \n",
    "        def __str__(self):\n",
    "            return \"[\" + \",\".join( [ str(element) for element in [self.type_node, self.feature_id, self.threshold, self.proba, self.__left, self.__right] ] ) + \"]\"\n",
    "\n",
    "    \n",
    "    def __init__(self, min_samples_split=2, max_depth=None, \n",
    "                 sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        #комментарии для себя:\n",
    "        #ожидается в dict:\n",
    "        #ключ - id, как при хранении дерева в массиве, так:\n",
    "        # 0 - слева 1, справа 2\n",
    "        # 1 - слева 2*1+1=3, справа 2*1+2=4\n",
    "        # 2 - слева 2*2+1=5, справа 2*2+2 = 6\n",
    "        # В самом объекте ожидается массив из 3 элементов, \n",
    "        # первый - код LEAF_TYPE, промежуточные NON_LEAF_TYPE, конечные - LEAF_TYPE\n",
    "        # для NON_LEAF_TYPE - 2 и 3 - feature_id, threshold\n",
    "        # для LEAF_TYPE - класс и вероятность\n",
    "        self.tree = MyDecisionTreeClassifier.Node()\n",
    "        \n",
    "        \n",
    "        # минимальное количество элементов в листе для разделения\n",
    "        self.min_samples_split = min_samples_split\n",
    "        #максимальная глубина\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        if self.max_depth==None:\n",
    "            self.max_depth = 20\n",
    "        #доля преобладающего класса\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        #функция критерии\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print ('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        #количество используемых призаков\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print ('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        #l_class_count, l_sizes, r_class_count, r_sizes\n",
    "        #См. выше в отладке\n",
    "        return gini(l_c, l_s, r_c, r_s)\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        #См. выше в отладке\n",
    "        return entropy(l_c, l_s, r_c, r_s)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        #См. выше в отладке\n",
    "        return misclass(l_c, l_s, r_c, r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        #См. выше в отладке\n",
    "        return get_feature_ids_sqrt(n_feature)\n",
    "    \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        #См. выше в отладке\n",
    "        return get_feature_ids_log2(n_feature)\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        #См. выше в отладке\n",
    "        return get_feature_ids_N(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "                \n",
    "# см. выше\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        #  см. выше\n",
    "        splitted_sorted_y = sorted_y\n",
    "        r_border_ids = np.where((splitted_sorted_y[:-1] != splitted_sorted_y[1:]) & (sorted_x[:-1] != sorted_x[1:]) )[0] + (1)\n",
    "        #здесь добавим код, который говорит, что и x должны быть разные\n",
    "        if len(r_border_ids) == 0:\n",
    "            return None, None\n",
    "        \n",
    "        #  см. выше\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), splitted_sorted_y[r_border_ids - 1]] = r_border_ids - np.append([0], r_border_ids[:-1])\n",
    "        \n",
    "        #  см. выше\n",
    "        l_class_count = np.cumsum(one_hot_code, axis=0)        \n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        \n",
    "        #как-то считаем критерий информативности, при этом возвращаем массив [1,2,34]\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        #находим минимальное значение\n",
    "        idx = np.argmin(gs)\n",
    "    \n",
    "        # значение границы\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        #возвращаем минимальное значение информативности и значение границы\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "    \n",
    "    def __fit_node(self, x_m, y_m, node, depth_m):\n",
    "       \n",
    "        lst = [[x_m, y_m, node, depth_m]]\n",
    "        \n",
    "        while len(lst)>0:\n",
    "            x, y, node, depth = lst.pop()\n",
    "            #придется делать через рекурсию, так как такой интерфейс, хотя для python не очень хорошо\n",
    "            #сначала определим что мы НЕ в LEAF:\n",
    "            type_leaf = self.NON_LEAF_TYPE\n",
    "            if self.max_depth is not None and depth >= self.max_depth:\n",
    "                type_leaf = self.LEAF_TYPE\n",
    "\n",
    "            share = np.max(np.unique(y, return_counts=True)[1])/y.shape[0]\n",
    "            if share >= self.sufficient_share:\n",
    "                type_leaf = self.LEAF_TYPE\n",
    "            if y.shape[0] <= self.min_samples_split:\n",
    "                 type_leaf = self.LEAF_TYPE\n",
    "\n",
    "            if type_leaf == self.LEAF_TYPE:\n",
    "                self.__process_leaf_node(y, node)\n",
    "                continue\n",
    "\n",
    "            #дальше определяем по каким признакам будем считать\n",
    "            features = self.get_feature_ids(x.shape[1])\n",
    "            find_feature = 0\n",
    "            find_value = None\n",
    "            find_threshold = None\n",
    "            find_gs = None\n",
    "            for feature in features:\n",
    "                value, threshold = self.__find_threshold( x[:, feature], y)\n",
    "                if value == None:\n",
    "                    continue\n",
    "                if find_value==None or find_value > value:\n",
    "                    find_feature = feature\n",
    "                    find_value = value\n",
    "                    find_threshold = threshold\n",
    "\n",
    "            if find_value == None:\n",
    "                #случай ошибки, если не смогли найти разделения\n",
    "                self.__process_leaf_node(y, node)\n",
    "                continue\n",
    "\n",
    "\n",
    "            x_l, x_r, y_l, y_r =self.__div_samples(x, y, find_feature, find_threshold)\n",
    "\n",
    "            self.__process_non_leaf_node(node, find_feature, find_threshold)\n",
    "\n",
    "            ##учим левую половину\n",
    "            lst.append([x_l, y_l, node.createLeft(), depth+1])\n",
    "            ##учим правую половину\n",
    "            lst.append([x_r, y_r, node.createRight(), depth+1])\n",
    "\n",
    "\n",
    "    def __process_leaf_node(self, y, node):\n",
    "        clas, count = np.unique(y, return_counts=True)\n",
    "        max_class = clas[np.argmax(count)]\n",
    "        probability = np.max(count) / y.shape[0]\n",
    "        \n",
    "        node.type_node = self.LEAF_TYPE\n",
    "        node.clazz = max_class \n",
    "        node.proba = probability\n",
    "    \n",
    "    def __process_non_leaf_node(self, node, feature_id, threshold):\n",
    "        node.type_node = self.NON_LEAF_TYPE\n",
    "        node.feature_id = feature_id \n",
    "        node.threshold = threshold\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, self.tree, 0) \n",
    "\n",
    "    def __predict_class(self, x, node):\n",
    "        if node.type_node == self.__class__.NON_LEAF_TYPE:\n",
    "            feature_id, threshold = node.feature_id, node.threshold\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, node.getLeft())\n",
    "            else:\n",
    "                return self.__predict_class(x, node.getRight())\n",
    "        else:\n",
    "            return node.clazz\n",
    "\n",
    "    def __predict_probs(self, x, node):\n",
    "        if node.type_node == self.__class__.NON_LEAF_TYPE:\n",
    "            feature_id, threshold = node.feature_id, node.threshold\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, node.getLeft())\n",
    "            else:\n",
    "                return self.__predict_probs(x, node.getRight())\n",
    "        else:\n",
    "            return node.proba\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, self.tree) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, self.tree) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120269, 11)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cs-training.csv', sep=',').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\app\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\app\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([111912,   8357], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930514097564626"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "111912/(111912+8357)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По хорошему - очень не равномерный dataset. И тупое предсказание 0 класса дало бы 0,93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, max_depth=8)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8451054096221924\n",
      "[0,5,56.5,None,[0,5,57.5,None,[1,(None,),None,1.0,None,None],[1,(None,),None,0.5,None,None]],[0,1,100.0,None,[0,7,1.0,None,[1,(None,),None,1.0,None,None],[0,9,0.5,None,[1,(None,),None,1.0,None,None],[0,1,101.5,None,[1,(None,),None,1.0,None,None],[1,(None,),None,0.5,None,None]]]],[0,4,243745.0,None,[0,5,16.5,None,[1,(None,),None,1.0,None,None],[0,3,0.023822465,None,[1,(None,),None,1.0,None,None],[0,3,0.017881928499999998,None,[1,(None,),None,1.0,None,None],[1,(None,),None,1.0,None,None]]]],[0,7,30.5,None,[1,(None,),None,1.0,None,None],[0,4,234800.0,None,[1,(None,),None,1.0,None,None],[0,4,226637.0,None,[1,(None,),None,1.0,None,None],[0,7,27.5,None,[1,(None,),None,1.0,None,None],[0,7,25.5,None,[1,(None,),None,1.0,None,None],[1,(None,),None,0.9305337225840258,None,None]]]]]]]]]\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "print(my_clf.tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9506881237030029\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорость работы медленней, но это связано с частым вызовом функции argsort. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321942296499542\n",
      "0.9307391702003824\n",
      "0.9324852415398687\n",
      "0.9289515257337657\n",
      "0.9280339250821104\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8927829051301239\n",
      "0.8962750478090962\n",
      "0.8939053795626507\n",
      "0.8924087469859483\n",
      "0.8905749802519436\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество, довольно близко"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8  - предварительная подготовка выполняется в соответствии с приведенной статьей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156 entries, 0 to 155\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    156 non-null int64\n",
      "Survived       156 non-null int64\n",
      "Pclass         156 non-null int64\n",
      "Name           156 non-null object\n",
      "Sex            156 non-null object\n",
      "Age            126 non-null float64\n",
      "SibSp          156 non-null int64\n",
      "Parch          156 non-null int64\n",
      "Ticket         156 non-null object\n",
      "Fare           156 non-null float64\n",
      "Cabin          31 non-null object\n",
      "Embarked       155 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 14.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.drop(['PassengerId'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
    "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
    "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
    "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
    "# we can now drop the cabin feature\n",
    "train_df = train_df.drop(['Cabin'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    mean = train_df[\"Age\"].mean()\n",
    "    std = train_df[\"Age\"].std()\n",
    "    is_null = dataset[\"Age\"].isnull().sum()\n",
    "    # compute random numbers between the mean, std and is_null\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = dataset[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"Age\"] = age_slice\n",
    "    dataset[\"Age\"] = train_df[\"Age\"].astype(int)\n",
    "train_df[\"Age\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_value = 'S'\n",
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156 entries, 0 to 155\n",
      "Data columns (total 11 columns):\n",
      "Survived    156 non-null int64\n",
      "Pclass      156 non-null int64\n",
      "Name        156 non-null object\n",
      "Sex         156 non-null object\n",
      "Age         156 non-null int32\n",
      "SibSp       156 non-null int64\n",
      "Parch       156 non-null int64\n",
      "Ticket      156 non-null object\n",
      "Fare        156 non-null float64\n",
      "Embarked    156 non-null object\n",
      "Deck        156 non-null int32\n",
      "dtypes: float64(1), int32(2), int64(4), object(4)\n",
      "memory usage: 12.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df]\n",
    "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "\n",
    "for dataset in data:\n",
    "    # extract titles\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    # replace titles with a more common title or as Rare\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
    "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    # convert titles into numbers\n",
    "    dataset['Title'] = dataset['Title'].map(titles)\n",
    "    # filling NaN with 0, to get safe\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "train_df = train_df.drop(['Name'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = {\"male\": 0, \"female\": 1}\n",
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Ticket'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(ports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df]\n",
    "for dataset in data:\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
    "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
    "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  Deck  Title\n",
       "0         0       3    0    2      1      0     0         0     8      1\n",
       "1         1       1    1    5      1      0     3         1     3      3\n",
       "2         1       3    1    3      0      0     0         0     8      2\n",
       "3         1       1    1    5      1      0     3         0     3      3\n",
       "4         0       3    0    5      0      0     1         0     8      1\n",
       "5         0       3    0    3      0      0     1         2     8      1\n",
       "6         0       1    0    6      0      0     3         0     5      1\n",
       "7         0       3    0    0      3      1     2         0     8      4\n",
       "8         1       3    1    3      0      2     1         0     8      3\n",
       "9         1       2    1    1      1      0     2         1     8      3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65625\n",
      "0.7419354838709677\n",
      "0.7741935483870968\n",
      "0.7741935483870968\n",
      "0.7741935483870968\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(X_train.values, Y_train.values):\n",
    "    x_train, y_train = X_train.iloc[train], Y_train.iloc[train]\n",
    "    x_test, y_test = X_train.iloc[test], Y_train.iloc[test]\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(x_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n",
      "0.7096774193548387\n",
      "0.6774193548387096\n",
      "0.7096774193548387\n",
      "0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(X_train.values, Y_train.values):\n",
    "    x_train, y_train = X_train.iloc[train], Y_train.iloc[train]\n",
    "    x_test, y_test = X_train.iloc[test], Y_train.iloc[test]\n",
    "    my_clf.fit(x_train.values, y_train.values)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(x_test.values), y_true=y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты близки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [10,20,30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875 10\n",
      "0.9032258064516129 10\n",
      "0.5806451612903226 10\n",
      "0.8387096774193549 10\n",
      "0.7096774193548387 10\n",
      "0.71875 20\n",
      "0.6129032258064516 20\n",
      "0.6451612903225806 20\n",
      "0.7741935483870968 20\n",
      "0.6451612903225806 20\n",
      "0.75 30\n",
      "0.7419354838709677 30\n",
      "0.8064516129032258 30\n",
      "0.6774193548387096 30\n",
      "0.6774193548387096 30\n"
     ]
    }
   ],
   "source": [
    "for depth in depths:\n",
    "    my_clf = MyDecisionTreeClassifier(min_samples_split=2, max_depth=depth)\n",
    "    for train, test in gkf.split(X_train.values, Y_train.values):\n",
    "        x_train, y_train = X_train.iloc[train], Y_train.iloc[train]\n",
    "        x_test, y_test = X_train.iloc[test], Y_train.iloc[test]\n",
    "        my_clf.fit(x_train.values, y_train.values)\n",
    "        print(accuracy_score(y_pred=my_clf.predict(x_test.values), y_true=y_test.values), depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше при максимальной глубине 20. Дальше начинается переобучение"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
