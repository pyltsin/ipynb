{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Весь код, который нужно разобрать, будем дебажить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[3,2],[4,4],[2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([[1], [2], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = x.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сортируем внутри строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[4, 4],\n",
       "         [3, 2]],\n",
       " \n",
       "        [[3, 2],\n",
       "         [4, 4]],\n",
       " \n",
       "        [[3, 2],\n",
       "         [4, 4]]]), array([[[2],\n",
       "         [1]],\n",
       " \n",
       "        [[1],\n",
       "         [2]],\n",
       " \n",
       "        [[1],\n",
       "         [2]]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_x, sorted_y = x[sorted_idx], y[sorted_idx]\n",
    "sorted_x, sorted_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пока непонятно что, скорее всего передаем ОДИН признак. Попробуем еще раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([7, 6, 5,4,3,2,1,0])\n",
    "y=np.array([1, 1, 1,1,0,0,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 5, 4, 3, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = x.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([2, 2, 0, 0, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_x, sorted_y = x[sorted_idx], y[sorted_idx]\n",
    "sorted_x, sorted_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсортировали значения по возрастанию признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_number = np.unique(y).shape[0]\n",
    "class_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили количество уникальный классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_sorted_y = sorted_y\n",
    "splitted_sorted_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удалил лишнее обрезание, так как это должно выполняться в другом методе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_sorted_y = sorted_y\n",
    "r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (1)\n",
    "\n",
    "r_border_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получили список, где будем делить (правые границы изменения классов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если класс по размеру не разделим, то возвращаем float('+inf'), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "one_hot_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодируем классы - количество строк - количество возможных делений, количество колоннок - количество классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_el_count = r_border_ids - np.append([0], r_border_ids[:-1])\n",
    "eq_el_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "количество одинаковых элементов (после отсечения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(r_border_ids.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получаем индексы для всех строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_y[r_border_ids - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получаем значения левых границ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "классы должны быть закодированы, начиная с 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "one_hot_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_el_count.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "class_increments        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(sorted_y[:], minlength=class_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_increments[0] = class_increments[0] \n",
    "class_increments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили количество классов КРОМЕ находящиегося справа на ВСЕЙ выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [2., 0., 2.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "l_class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "наконец-то получили количество классов слева при разделении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 4., 0.],\n",
       "       [0., 4., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_class_count = np.bincount(y) - l_class_count\n",
    "r_class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получили количество классов справа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "l_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сумма классов слева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_sizes = sorted_y.shape[0] - l_sizes\n",
    "r_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сумма классов справа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С кодом разобрались. Теперь тестируем критерии информативности.\n",
    "Так как берется левая и правая часть и берется минимум, то просто берем сумму левой и правой части по информативности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def gini(l_c, l_s, r_c, r_s):\n",
    "        #l_class_count, l_sizes, r_class_count, r_sizes\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        \n",
    "        sum_l = np.sum(np.power(l_c, 2), axis=1)\n",
    "        c_l = np.power(l_s.reshape([1, l_s.shape[0]*l_s.shape[1]])[0], 2)\n",
    "        \n",
    "        sum_r = np.sum(np.power(r_c, 2), axis=1)\n",
    "        c_r = np.power(r_s.reshape([1, r_s.shape[0]*r_s.shape[1]])[0], 2)\n",
    "        return 2 - sum_l/c_l - sum_r/c_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44444444, 0.5       ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(l_class_count, l_sizes, r_class_count, r_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 2.],\n",
       "        [2., 0., 2.]]), array([[2],\n",
       "        [4]], dtype=int64), array([[2., 4., 0.],\n",
       "        [0., 4., 0.]]), array([[6],\n",
       "        [4]], dtype=int64))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_class_count, l_sizes, r_class_count, r_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4444444444444444, 0.5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-4/4+1-4/36-16/36, 1-8/16+1-16/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совпало. Идем дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 1. ],\n",
       "       [0.5, 0. , 0.5]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_class_count/l_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(l_c, l_s, r_c, r_s):\n",
    "    p_l = l_c/l_s\n",
    "    p_r = r_c/r_s\n",
    "    p_ll = np.log2(p_l, where = p_l!=0)\n",
    "    p_rl = np.log2(p_r,  where = p_r!=0)\n",
    "    return - np.sum(p_l*p_ll, axis=1) - np.sum(p_r*p_rl, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91829583, 1.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(l_class_count, l_sizes, r_class_count, r_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclass(l_c, l_s, r_c, r_s):\n",
    "    p_l = l_c/l_s\n",
    "    p_r = r_c/r_s\n",
    "    m_l = np.max(p_l, axis=1)\n",
    "    m_r = np.max(p_r, axis=1)\n",
    "    return 2 - m_l - m_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.5       ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass(l_class_count, l_sizes, r_class_count, r_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь определения индексов feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_ids_sqrt(n_feature):\n",
    "    feature_ids = np.arange(n_feature)\n",
    "    np.random.shuffle(feature_ids)\n",
    "    return feature_ids[:int(n_feature**0.5)]\n",
    "        \n",
    "def get_feature_ids_log2(n_feature):\n",
    "    feature_ids = np.arange(n_feature)\n",
    "    np.random.shuffle(feature_ids)\n",
    "    return feature_ids[:int(math.log2(n_feature))]\n",
    "\n",
    "def get_feature_ids_N(n_feature):\n",
    "    return np.arange(n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_ids_sqrt(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_ids_log2(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_ids_N(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "все кажется нормально"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идут куски тестирования итеративного алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.array([1,3,4,3,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.unique(ar, return_counts=True)[1])/ar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas, count = np.unique(ar, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 3, 4]), array([1, 1, 3, 1], dtype=int64))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.array([[1,2],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, \n",
    "                 sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        #комментарии для себя:\n",
    "        #ожидается в dict:\n",
    "        #ключ - id, как при хранении дерева в массиве, так:\n",
    "        # 0 - слева 1, справа 2\n",
    "        # 1 - слева 2*1+1=3, справа 2*1+2=4\n",
    "        # 2 - слева 2*2+1=5, справа 2*2+2 = 6\n",
    "        # В самом объекте ожидается массив из 3 элементов, \n",
    "        # первый - код LEAF_TYPE, промежуточные NON_LEAF_TYPE, конечные - LEAF_TYPE\n",
    "        # для NON_LEAF_TYPE - 2 и 3 - feature_id, threshold\n",
    "        # для LEAF_TYPE - класс и вероятность\n",
    "        self.tree = dict()\n",
    "        \n",
    "        \n",
    "        # минимальное количество элементов в листе для разделения\n",
    "        self.min_samples_split = min_samples_split\n",
    "        #максимальная глубина\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        if self.max_depth==None:\n",
    "            self.max_depth = 20\n",
    "        #доля преобладающего класса\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        #функция критерии\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print ('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        #количество используемых призаков\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print ('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        #l_class_count, l_sizes, r_class_count, r_sizes\n",
    "        #См. выше в отладке\n",
    "        return gini(l_c, l_s, r_c, r_s)\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        #См. выше в отладке\n",
    "        return entropy(l_c, l_s, r_c, r_s)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        #См. выше в отладке\n",
    "        return misclass(l_c, l_s, r_c, r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        #См. выше в отладке\n",
    "        return get_feature_ids_sqrt(n_feature)\n",
    "    \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        #См. выше в отладке\n",
    "        return get_feature_ids_log2(n_feature)\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        #См. выше в отладке\n",
    "        return get_feature_ids_N(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # см. выше\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        #  см. выше\n",
    "        splitted_sorted_y = sorted_y\n",
    "        r_border_ids = np.where((splitted_sorted_y[:-1] != splitted_sorted_y[1:]) & (sorted_x[:-1] != sorted_x[1:]) )[0] + (1)\n",
    "        #здесь добавим код, который говорит, что и x должны быть разные\n",
    "        #print('sorted_y')\n",
    "        #print(sorted_y)\n",
    "\n",
    "        #print('r_border_ids')\n",
    "        #print(r_border_ids)\n",
    "        if len(r_border_ids) == 0:\n",
    "            return None, None\n",
    "        \n",
    "        #  см. выше\n",
    "        eq_el_count = r_border_ids - np.append([0], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] \n",
    "        \n",
    "        #  см. выше\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        \n",
    "        #как-то считаем критерий информативности, при этом возвращаем массив [1,2,34]\n",
    "        #print('\\n')\n",
    "        #print(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        #находим минимальное значение\n",
    "        idx = np.argmin(gs)\n",
    "    \n",
    "        # значение границы\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        #print('left_el_id')\n",
    "        #print(left_el_id)\n",
    "        #print('sorted_x[left_el_id-1]', 'sorted_x[left_el_id]')\n",
    "        #print(sorted_x[left_el_id-1], sorted_x[left_el_id])\n",
    "        #возвращаем минимальное значение информативности и значение границы\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x_m, y_m, node_id_m, depth_m):\n",
    "        # Ваш код\n",
    "        # Необходимо использовать следующее:\n",
    "        # self.LEAF_TYPE\n",
    "        # self.NON_LEAF_TYPE\n",
    "\n",
    "        # self.tree\n",
    "        # self.max_depth\n",
    "        # self.sufficient_share\n",
    "        # self.min_samples_split\n",
    "\n",
    "        # self.get_feature_ids\n",
    "        # self.__find_threshold\n",
    "        # self.__div_samples\n",
    "        # self.__fit_node\n",
    "        \n",
    "        lst = [[x_m, y_m, node_id_m, depth_m]]\n",
    "        \n",
    "        while len(lst)>0:\n",
    "            x, y, node_id, depth = lst.pop()\n",
    "            #придется делать через рекурсию, так как такой интерфейс, хотя для python не очень хорошо\n",
    "            #сначала определим что мы НЕ в LEAF:\n",
    "            type_leaf = self.NON_LEAF_TYPE\n",
    "            if self.max_depth is not None and depth >= self.max_depth:\n",
    "                type_leaf = self.LEAF_TYPE\n",
    "\n",
    "            share = np.max(np.unique(y, return_counts=True)[1])/y.shape[0]\n",
    "            if share >= self.sufficient_share:\n",
    "                type_leaf = self.LEAF_TYPE\n",
    "            if y.shape[0] <= self.min_samples_split:\n",
    "                 type_leaf = self.LEAF_TYPE\n",
    "\n",
    "            if type_leaf == self.LEAF_TYPE:\n",
    "                self.__process_leaf_node(y, node_id)\n",
    "                continue\n",
    "\n",
    "            #дальше определяем по каким признакам будем считать\n",
    "            features = self.get_feature_ids(x.shape[1])\n",
    "            find_feature = 0\n",
    "            find_value = None\n",
    "            find_threshold = None\n",
    "            find_gs = None\n",
    "            for feature in features:\n",
    "                value, threshold = self.__find_threshold( x[:, feature], y)\n",
    "                if value == None:\n",
    "                    continue\n",
    "                if find_value==None or find_value > value:\n",
    "                    find_feature = feature\n",
    "                    find_value = value\n",
    "                    find_threshold = threshold\n",
    "            #print('x[:, feature]')\n",
    "            #print(x[:, find_feature])\n",
    "            #print('y')\n",
    "            #print(y)\n",
    "            #print('value', 'find_threshold')\n",
    "            #print(value, find_threshold)\n",
    "\n",
    "            if find_value == None:\n",
    "                #случай ошибки, если не смогли найти разделения\n",
    "                self.__process_leaf_node(y, node_id)\n",
    "                return\n",
    "\n",
    "\n",
    "            x_l, x_r, y_l, y_r =self.__div_samples(x, y, find_feature, find_threshold)\n",
    "\n",
    "            self.__process_non_leaf_node(node_id, find_feature, find_threshold)\n",
    "\n",
    "            #print('len(y_l)', 'len(y_r)')\n",
    "            #print(len(y_l), len(y_r))\n",
    "            #print(np.unique(y_l), np.unique(y_r))\n",
    "            ##учим левую половину\n",
    "            lst.append([x_l, y_l, 2*node_id+1, depth+1])\n",
    "            lst.append([x_r, y_r, 2*node_id+2, depth+1])\n",
    "\n",
    "\n",
    "    def __process_leaf_node(self, y, node_id):\n",
    "        clas, count = np.unique(y, return_counts=True)\n",
    "        max_class = clas[np.argmax(count)]\n",
    "        probability = np.max(count) / y.shape[0]\n",
    "        #print(node_id)\n",
    "        self.tree[node_id] = [self.LEAF_TYPE, max_class , probability]\n",
    "    \n",
    "    def __process_non_leaf_node(self, node_id, feature, threshold):\n",
    "        #print(node_id)\n",
    "        self.tree[node_id] = [self.NON_LEAF_TYPE, feature , threshold]\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120269, 11)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cs-training.csv', sep=',').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\app\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\app\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([111912,   8357], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930514097564626"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "111912/(111912+8357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, max_depth=8)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8130269050598145\n",
      "{0: [0, 5, 56.5], 2: [0, 1, 100.0], 6: [0, 4, 243745.0], 14: [0, 7, 30.5], 30: [0, 4, 234800.0], 62: [0, 4, 226637.0], 126: [0, 7, 27.5], 254: [0, 7, 25.5], 510: [1, 0, 0.9305337225840258], 509: [1, 0, 1.0], 253: [1, 1, 1.0], 125: [1, 1, 1.0], 61: [1, 0, 1.0], 29: [1, 0, 1.0], 13: [0, 5, 16.5], 28: [0, 3, 0.023822465], 58: [0, 3, 0.017881928499999998], 118: [1, 0, 1.0], 117: [1, 1, 1.0], 57: [1, 0, 1.0], 27: [1, 0, 1.0], 5: [0, 7, 1.0], 12: [0, 9, 0.5], 26: [0, 1, 101.5], 54: [1, 0, 0.5], 53: [1, 0, 1.0], 25: [1, 0, 1.0], 11: [1, 0, 1.0], 1: [0, 5, 57.5], 4: [1, 0, 0.5], 3: [1, 0, 1.0], 508: [1, 0, 0.8333333333333334], 507: [1, 0, 1.0], 124: [1, 0, 0.5], 123: [1, 0, 1.0], 252: [1, 0, 0.5], 506: [1, 0, 1.0], 505: [1, 1, 1.0], 251: [1, 0, 1.0], 60: [1, 0, 0.5], 59: [1, 0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "print(my_clf.tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8730006217956543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.tree._tree.Tree at 0x1d53354f2a0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9291593913694188\n",
      "0.934979629167706\n",
      "0.9300740001662925\n",
      "0.930905462708905\n",
      "0.9272440028270902\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8895817743410659\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
