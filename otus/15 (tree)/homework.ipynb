{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Весь код, который нужно разобрать, будем дебажить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[3,2],[4,4],[2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([[1], [2], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = x.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сортируем внутри строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[4, 4],\n",
       "         [3, 2]],\n",
       " \n",
       "        [[3, 2],\n",
       "         [4, 4]],\n",
       " \n",
       "        [[3, 2],\n",
       "         [4, 4]]]), array([[[2],\n",
       "         [1]],\n",
       " \n",
       "        [[1],\n",
       "         [2]],\n",
       " \n",
       "        [[1],\n",
       "         [2]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_x, sorted_y = x[sorted_idx], y[sorted_idx]\n",
    "sorted_x, sorted_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пока непонятно что, скорее всего передаем ОДИН признак. Попробуем еще раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([7, 6, 5,4,3,2,1,0])\n",
    "y=np.array([1, 1, 1,1,0,0,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 5, 4, 3, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = x.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([2, 2, 0, 0, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_x, sorted_y = x[sorted_idx], y[sorted_idx]\n",
    "sorted_x, sorted_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсортировали значения по возрастанию признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_number = np.unique(y).shape[0]\n",
    "class_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили количество уникальный классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_sorted_y = sorted_y\n",
    "splitted_sorted_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удалил лишнее обрезание, так как это должно выполняться в другом методе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_sorted_y = sorted_y\n",
    "r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (1)\n",
    "\n",
    "r_border_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получили список, где будем делить (правые границы изменения классов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если класс по размеру не разделим, то возвращаем float('+inf'), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "one_hot_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодируем классы - количество строк - количество возможных делений, количество колоннок - количество классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_el_count = r_border_ids - np.append([0], r_border_ids[:-1])\n",
    "eq_el_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "количество одинаковых элементов (после отсечения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(r_border_ids.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получаем индексы для всех строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_y[r_border_ids - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получаем значения левых границ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "классы должны быть закодированы, начиная с 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "one_hot_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_el_count.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "class_increments        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(sorted_y[:], minlength=class_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_increments[0] = class_increments[0] \n",
    "class_increments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили количество классов КРОМЕ находящиегося справа на ВСЕЙ выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [2., 0., 2.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "l_class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "наконец-то получили количество классов слева при разделении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 4., 0.],\n",
       "       [0., 4., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_class_count = np.bincount(y) - l_class_count\n",
    "r_class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получили количество классов справа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "l_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сумма классов слева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_sizes = sorted_y.shape[0] - l_sizes\n",
    "r_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сумма классов справа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С кодом разобрались. Теперь тестируем критерии информативности.\n",
    "Так как берется левая и правая часть и берется минимум, то просто берем сумму левой и правой части по информативности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def gini(l_c, l_s, r_c, r_s):\n",
    "        #l_class_count, l_sizes, r_class_count, r_sizes\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        \n",
    "        sum_l = np.sum(np.power(l_c, 2), axis=1)\n",
    "        c_l = np.power(l_s.reshape([1, l_s.shape[0]*l_s.shape[1]])[0], 2)\n",
    "        \n",
    "        sum_r = np.sum(np.power(r_c, 2), axis=1)\n",
    "        c_r = np.power(r_s.reshape([1, r_s.shape[0]*r_s.shape[1]])[0], 2)\n",
    "        return 2 - sum_l/c_l - sum_r/c_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44444444, 0.5       ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(l_class_count, l_sizes, r_class_count, r_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 2.],\n",
       "        [2., 0., 2.]]), array([[2],\n",
       "        [4]], dtype=int64), array([[2., 4., 0.],\n",
       "        [0., 4., 0.]]), array([[6],\n",
       "        [4]], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_class_count, l_sizes, r_class_count, r_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4444444444444444, 0.5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-4/4+1-4/36-16/36, 1-8/16+1-16/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совпало. Идем дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 1. ],\n",
       "       [0.5, 0. , 0.5]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_class_count/l_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(l_c, l_s, r_c, r_s):\n",
    "    p_l = l_c/l_s\n",
    "    p_r = r_c/r_s\n",
    "    p_ll = np.log2(p_l, where = p_l!=0)\n",
    "    p_rl = np.log2(p_r,  where = p_r!=0)\n",
    "    return - np.sum(p_l*p_ll, axis=1) - np.sum(p_r*p_rl, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91829583, 1.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(l_class_count, l_sizes, r_class_count, r_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclass(l_c, l_s, r_c, r_s):\n",
    "    p_l = l_c/l_s\n",
    "    p_r = r_c/r_s\n",
    "    m_l = np.max(p_l, axis=1)\n",
    "    m_r = np.max(p_r, axis=1)\n",
    "    return 2 - m_l - m_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.5       ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass(l_class_count, l_sizes, r_class_count, r_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь определения индексов feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_ids_sqrt(n_feature):\n",
    "    feature_ids = np.arange(n_feature)\n",
    "    np.random.shuffle(feature_ids)\n",
    "    return feature_ids[:int(n_feature**0.5)]\n",
    "        \n",
    "def get_feature_ids_log2(n_feature):\n",
    "    feature_ids = np.arange(n_feature)\n",
    "    np.random.shuffle(feature_ids)\n",
    "    return feature_ids[:int(math.log2(n_feature))]\n",
    "\n",
    "def get_feature_ids_N(n_feature):\n",
    "    return np.arange(n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_ids_sqrt(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_ids_log2(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_ids_N(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "все кажется нормально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, \n",
    "                 sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        #комментарии для себя:\n",
    "        #ожидается в dict:\n",
    "        #ключ - id, как при хранении дерева в массиве, так:\n",
    "        # 0 - слева 1, справа 2\n",
    "        # 1 - слева 2*1+1=3, справа 2*1+2=4\n",
    "        # 2 - слева 2*2+1=5, справа 2*2+2 = 6\n",
    "        # В самом объекте ожидается массив из 3 элементов, \n",
    "        # первый - код LEAF_TYPE, промежуточные NON_LEAF_TYPE, конечные - LEAF_TYPE\n",
    "        # для NON_LEAF_TYPE - 2 и 3 - feature_id, threshold\n",
    "        # для LEAF_TYPE - класс и вероятность\n",
    "        self.tree = dict()\n",
    "        \n",
    "        \n",
    "        # минимальное количество элементов в листе для разделения\n",
    "        self.min_samples_split = min_samples_split\n",
    "        #максимальная глубина\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        if self.max_depth==None:\n",
    "            self.max_depth = 20\n",
    "        #доля преобладающего класса\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        #функция критерии\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print ('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        #количество используемых призаков\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print ('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        #l_class_count, l_sizes, r_class_count, r_sizes\n",
    "        #См. выше в отладке\n",
    "        return gini(l_c, l_s, r_c, r_s)\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        #См. выше в отладке\n",
    "        return entropy(l_c, l_s, r_c, r_s)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        #См. выше в отладке\n",
    "        return misclass(l_c, l_s, r_c, r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        #См. выше в отладке\n",
    "        return get_feature_ids_sqrt(n_feature)\n",
    "    \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        #См. выше в отладке\n",
    "        return get_feature_ids_log2(n_feature)\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        #См. выше в отладке\n",
    "        return get_feature_ids_N(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # см. выше\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        #  см. выше\n",
    "        splitted_sorted_y = sorted_y\n",
    "        r_border_ids = np.where((splitted_sorted_y[:-1] != splitted_sorted_y[1:]) & (sorted_x[:-1] != sorted_x[1:]) )[0] + (1)\n",
    "        #здесь добавим код, который говорит, что и x должны быть разные\n",
    "        if len(r_border_ids) == 0:\n",
    "            return None, None\n",
    "        \n",
    "        #  см. выше\n",
    "        eq_el_count = r_border_ids - np.append([0], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        \n",
    "        #  см. выше\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        \n",
    "        #как-то считаем критерий информативности, при этом возвращаем массив [1,2,34]\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        #находим минимальное значение\n",
    "        idx = np.argmin(gs)\n",
    "    \n",
    "        # значение границы\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        #возвращаем минимальное значение информативности и значение границы\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x_m, y_m, node_id_m, depth_m):\n",
    "        # Ваш код\n",
    "        # Необходимо использовать следующее:\n",
    "        # self.LEAF_TYPE\n",
    "        # self.NON_LEAF_TYPE\n",
    "\n",
    "        # self.tree\n",
    "        # self.max_depth\n",
    "        # self.sufficient_share\n",
    "        # self.min_samples_split\n",
    "\n",
    "        # self.get_feature_ids\n",
    "        # self.__find_threshold\n",
    "        # self.__div_samples\n",
    "        # self.__fit_node\n",
    "        \n",
    "        lst = [[x_m, y_m, node_id_m, depth_m]]\n",
    "        \n",
    "        while len(lst)>0:\n",
    "            x, y, node_id, depth = lst.pop()\n",
    "            #придется делать через рекурсию, так как такой интерфейс, хотя для python не очень хорошо\n",
    "            #сначала определим что мы НЕ в LEAF:\n",
    "            type_leaf = self.NON_LEAF_TYPE\n",
    "            if self.max_depth is not None and depth >= self.max_depth:\n",
    "                type_leaf = self.LEAF_TYPE\n",
    "\n",
    "            share = np.max(np.unique(y, return_counts=True)[1])/y.shape[0]\n",
    "            if share >= self.sufficient_share:\n",
    "                type_leaf = self.LEAF_TYPE\n",
    "            if y.shape[0] <= self.min_samples_split:\n",
    "                 type_leaf = self.LEAF_TYPE\n",
    "\n",
    "            if type_leaf == self.LEAF_TYPE:\n",
    "                self.__process_leaf_node(y, node_id)\n",
    "                continue\n",
    "\n",
    "            #дальше определяем по каким признакам будем считать\n",
    "            features = self.get_feature_ids(x.shape[1])\n",
    "            find_feature = 0\n",
    "            find_value = None\n",
    "            find_threshold = None\n",
    "            find_gs = None\n",
    "            for feature in features:\n",
    "                value, threshold = self.__find_threshold( x[:, feature], y)\n",
    "                if value == None:\n",
    "                    continue\n",
    "                if find_value==None or find_value > value:\n",
    "                    find_feature = feature\n",
    "                    find_value = value\n",
    "                    find_threshold = threshold\n",
    "\n",
    "            if find_value == None:\n",
    "                #случай ошибки, если не смогли найти разделения\n",
    "                self.__process_leaf_node(y, node_id)\n",
    "                continue\n",
    "\n",
    "\n",
    "            x_l, x_r, y_l, y_r =self.__div_samples(x, y, find_feature, find_threshold)\n",
    "\n",
    "            self.__process_non_leaf_node(node_id, find_feature, find_threshold)\n",
    "\n",
    "            lst.append([x_l, y_l, 2*node_id+1, depth+1])\n",
    "            lst.append([x_r, y_r, 2*node_id+2, depth+1])\n",
    "\n",
    "\n",
    "    def __process_leaf_node(self, y, node_id):\n",
    "        clas, count = np.unique(y, return_counts=True)\n",
    "        max_class = clas[np.argmax(count)]\n",
    "        probability = np.max(count) / y.shape[0]\n",
    "        self.tree[node_id] = [self.LEAF_TYPE, max_class , probability]\n",
    "    \n",
    "    def __process_non_leaf_node(self, node_id, feature, threshold):\n",
    "        self.tree[node_id] = [self.NON_LEAF_TYPE, feature , threshold]\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120269, 11)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cs-training.csv', sep=',').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([111912,   8357], dtype=int64)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930514097564626"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "111912/(111912+8357)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По хорошему - очень не равномерный dataset. И тупое предсказание 0 класса дало бы 0,93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, max_depth=8)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.6890261173248291\n",
      "{0: [0, 5, 56.5], 2: [0, 1, 100.0], 6: [0, 4, 243745.0], 14: [0, 7, 30.5], 30: [0, 4, 234800.0], 62: [0, 4, 226637.0], 126: [0, 7, 27.5], 254: [0, 7, 25.5], 510: [1, 0, 0.9305337225840258], 509: [1, 0, 1.0], 253: [1, 1, 1.0], 125: [1, 1, 1.0], 61: [1, 0, 1.0], 29: [1, 0, 1.0], 13: [0, 5, 16.5], 28: [0, 3, 0.023822465], 58: [0, 3, 0.017881928499999998], 118: [1, 0, 1.0], 117: [1, 1, 1.0], 57: [1, 0, 1.0], 27: [1, 0, 1.0], 5: [0, 7, 1.0], 12: [0, 9, 0.5], 26: [0, 1, 101.5], 54: [1, 0, 0.5], 53: [1, 0, 1.0], 25: [1, 0, 1.0], 11: [1, 0, 1.0], 1: [0, 5, 57.5], 4: [1, 0, 0.5], 3: [1, 0, 1.0]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         8314 function calls in 0.688 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "      150    0.352    0.002    0.352    0.002 {method 'argsort' of 'numpy.ndarray' objects}\n",
       "      150    0.087    0.001    0.439    0.003 <ipython-input-225-097a65e6f2fc>:77(__sort_samples)\n",
       "      198    0.078    0.000    0.078    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
       "       15    0.043    0.003    0.043    0.003 <ipython-input-225-097a65e6f2fc>:81(__div_samples)\n",
       "      119    0.041    0.000    0.048    0.000 <ipython-input-26-2e9293a69d21>:1(gini)\n",
       "      150    0.022    0.000    0.624    0.004 <ipython-input-225-097a65e6f2fc>:86(__find_threshold)\n",
       "      119    0.020    0.000    0.020    0.000 {built-in method numpy.core.multiarray.bincount}\n",
       "      198    0.013    0.000    0.096    0.000 arraysetops.py:268(_unique1d)\n",
       "        1    0.007    0.007    0.687    0.687 <ipython-input-225-097a65e6f2fc>:121(__fit_node)\n",
       "      285    0.006    0.000    0.006    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "      150    0.006    0.000    0.006    0.000 {built-in method numpy.core.multiarray.where}\n",
       "      198    0.004    0.000    0.004    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
       "      119    0.002    0.000    0.002    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
       "      238    0.001    0.000    0.001    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "      681    0.001    0.000    0.001    0.000 {built-in method numpy.core.multiarray.array}\n",
       "      285    0.001    0.000    0.006    0.000 fromnumeric.py:64(_wrapreduction)\n",
       "      166    0.001    0.000    0.001    0.000 {built-in method numpy.core.multiarray.concatenate}\n",
       "      134    0.001    0.000    0.001    0.000 {built-in method numpy.core.multiarray.arange}\n",
       "      198    0.001    0.000    0.097    0.000 arraysetops.py:121(unique)\n",
       "      119    0.000    0.000    0.000    0.000 {method 'argmin' of 'numpy.ndarray' objects}\n",
       "      198    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.empty}\n",
       "      119    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.zeros}\n",
       "      119    0.000    0.000    0.049    0.000 <ipython-input-225-097a65e6f2fc>:52(__gini)\n",
       "       47    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
       "      238    0.000    0.000    0.007    0.000 fromnumeric.py:1821(sum)\n",
       "      476    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "      119    0.000    0.000    0.002    0.000 function_base.py:4476(append)\n",
       "      301    0.000    0.000    0.003    0.000 fromnumeric.py:49(_wrapfunc)\n",
       "       47    0.000    0.000    0.000    0.000 function_base.py:1079(diff)\n",
       "      681    0.000    0.000    0.001    0.000 numeric.py:504(asanyarray)\n",
       "      119    0.000    0.000    0.000    0.000 fromnumeric.py:1471(ravel)\n",
       "      119    0.000    0.000    0.002    0.000 fromnumeric.py:2092(cumsum)\n",
       "      198    0.000    0.000    0.000    0.000 arraysetops.py:113(_unpack_tuple)\n",
       "      119    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "      357    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
       "      119    0.000    0.000    0.001    0.000 fromnumeric.py:1040(argmin)\n",
       "      301    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
       "      285    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
       "      380    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
       "       16    0.000    0.000    0.001    0.000 <ipython-input-225-097a65e6f2fc>:186(__process_leaf_node)\n",
       "       47    0.000    0.000    0.000    0.000 fromnumeric.py:2227(amax)\n",
       "       15    0.000    0.000    0.000    0.000 <ipython-input-225-097a65e6f2fc>:192(__process_non_leaf_node)\n",
       "       47    0.000    0.000    0.000    0.000 fromnumeric.py:1577(nonzero)\n",
       "        1    0.000    0.000    0.688    0.688 {built-in method builtins.exec}\n",
       "       16    0.000    0.000    0.000    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
       "       47    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.normalize_axis_index}\n",
       "       31    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "       15    0.000    0.000    0.000    0.000 <ipython-input-225-097a65e6f2fc>:73(__get_feature_ids_N)\n",
       "       15    0.000    0.000    0.000    0.000 <ipython-input-36-8fbc1cf0c5b2>:11(get_feature_ids_N)\n",
       "       16    0.000    0.000    0.000    0.000 fromnumeric.py:976(argmax)\n",
       "        1    0.000    0.000    0.688    0.688 <ipython-input-225-097a65e6f2fc>:195(fit)\n",
       "       30    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
       "        1    0.000    0.000    0.688    0.688 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = time()\n",
    "%prun my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "print(my_clf.tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.8640272617340088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         195 function calls in 0.862 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    0.853    0.853    0.853    0.853 {method 'build' of 'sklearn.tree._tree.DepthFirstTreeBuilder' objects}\n",
       "       14    0.003    0.000    0.003    0.000 {built-in method numpy.core.multiarray.array}\n",
       "        2    0.001    0.001    0.005    0.002 arraysetops.py:268(_unique1d)\n",
       "        1    0.001    0.001    0.001    0.001 {method 'argsort' of 'numpy.ndarray' objects}\n",
       "        1    0.001    0.001    0.001    0.001 {method 'sort' of 'numpy.ndarray' objects}\n",
       "        2    0.001    0.000    0.001    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
       "        2    0.001    0.000    0.001    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.862    0.862 tree.py:761(fit)\n",
       "        1    0.000    0.000    0.862    0.862 tree.py:111(fit)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.zeros}\n",
       "        2    0.000    0.000    0.003    0.002 validation.py:362(check_array)\n",
       "        1    0.000    0.000    0.862    0.862 {built-in method builtins.exec}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.empty}\n",
       "        1    0.000    0.000    0.001    0.001 multiclass.py:174(type_of_target)\n",
       "        2    0.000    0.000    0.001    0.000 validation.py:40(_assert_all_finite)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
       "        2    0.000    0.000    0.005    0.002 arraysetops.py:121(unique)\n",
       "        2    0.000    0.000    0.000    0.000 validation.py:153(_shape_repr)\n",
       "       21    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
       "        2    0.000    0.000    0.000    0.000 warnings.py:170(_add_filter)\n",
       "       18    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
       "        2    0.000    0.000    0.000    0.000 warnings.py:482(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:64(_wrapreduction)\n",
       "        2    0.000    0.000    0.000    0.000 warnings.py:463(__enter__)\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:49(_wrapfunc)\n",
       "        5    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
       "        2    0.000    0.000    0.000    0.000 validation.py:127(_num_samples)\n",
       "        6    0.000    0.000    0.000    0.000 abc.py:137(__instancecheck__)\n",
       "        2    0.000    0.000    0.000    0.000 warnings.py:442(__init__)\n",
       "        4    0.000    0.000    0.002    0.001 numeric.py:433(asarray)\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:12(get_config)\n",
       "        5    0.000    0.000    0.000    0.000 base.py:1187(isspmatrix)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 warnings.py:154(simplefilter)\n",
       "        1    0.000    0.000    0.001    0.001 _methods.py:34(_sum)\n",
       "        1    0.000    0.000    0.000    0.000 shape_base.py:11(atleast_1d)\n",
       "        5    0.000    0.000    0.000    0.000 validation.py:180(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 validation.py:355(_ensure_no_complex_data)\n",
       "        1    0.000    0.000    0.000    0.000 validation.py:800(check_random_state)\n",
       "        1    0.000    0.000    0.000    0.000 multiclass.py:111(is_multilabel)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
       "        5    0.000    0.000    0.000    0.000 abc.py:141(__subclasscheck__)\n",
       "        7    0.000    0.000    0.000    0.000 numeric.py:504(asanyarray)\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2227(amax)\n",
       "        1    0.000    0.000    0.862    0.862 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2092(cumsum)\n",
       "        2    0.000    0.000    0.000    0.000 arraysetops.py:113(_unpack_tuple)\n",
       "        1    0.000    0.000    0.001    0.001 {method 'sum' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:185(reshape)\n",
       "        1    0.000    0.000    0.001    0.001 multiclass.py:157(check_classification_targets)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
       "       12    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:556(ascontiguousarray)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
       "        1    0.000    0.000    0.000    0.000 function_base.py:689(copy)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 base.py:520(is_classifier)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = time()\n",
    "%prun clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорость работы медленней, но это связано с частым вызовом функции argsort. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9299492807849007\n",
      "0.9290346719880269\n",
      "0.9318200715057786\n",
      "0.9304481583104681\n",
      "0.9312351889577184\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8924918932402095\n",
      "0.8925334663673401\n",
      "0.8917020038247278\n",
      "0.8948615614866551\n",
      "0.8925705733172578\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество, довольно близко"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8  - предварительная подготовка выполняется в соответствии с приведенной статьей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.drop(['PassengerId'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
    "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
    "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
    "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
    "# we can now drop the cabin feature\n",
    "train_df = train_df.drop(['Cabin'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    mean = train_df[\"Age\"].mean()\n",
    "    std = train_df[\"Age\"].std()\n",
    "    is_null = dataset[\"Age\"].isnull().sum()\n",
    "    # compute random numbers between the mean, std and is_null\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = dataset[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"Age\"] = age_slice\n",
    "    dataset[\"Age\"] = train_df[\"Age\"].astype(int)\n",
    "train_df[\"Age\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_value = 'S'\n",
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null int32\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Ticket      891 non-null object\n",
      "Fare        891 non-null float64\n",
      "Embarked    891 non-null object\n",
      "Deck        891 non-null int32\n",
      "dtypes: float64(1), int32(2), int64(4), object(4)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df]\n",
    "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "\n",
    "for dataset in data:\n",
    "    # extract titles\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    # replace titles with a more common title or as Rare\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
    "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    # convert titles into numbers\n",
    "    dataset['Title'] = dataset['Title'].map(titles)\n",
    "    # filling NaN with 0, to get safe\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "train_df = train_df.drop(['Name'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = {\"male\": 0, \"female\": 1}\n",
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Ticket'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(ports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df]\n",
    "for dataset in data:\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
    "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
    "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  Deck  Title\n",
       "0         0       3    0    2      1      0     0         0     8      1\n",
       "1         1       1    1    5      1      0     3         1     3      3\n",
       "2         1       3    1    3      0      0     0         0     8      2\n",
       "3         1       1    1    5      1      0     3         0     3      3\n",
       "4         0       3    0    5      0      0     1         0     8      1\n",
       "5         0       3    0    3      0      0     1         2     8      1\n",
       "6         0       1    0    6      0      0     3         0     5      1\n",
       "7         0       3    0    0      3      1     2         0     8      4\n",
       "8         1       3    1    3      0      2     1         0     8      3\n",
       "9         1       2    1    1      1      0     2         1     8      3"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.770949720670391\n",
      "0.7808988764044944\n",
      "0.7808988764044944\n",
      "0.848314606741573\n",
      "0.8426966292134831\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(X_train.values, Y_train.values):\n",
    "    x_train, y_train = X_train.iloc[train], Y_train.iloc[train]\n",
    "    x_test, y_test = X_train.iloc[test], Y_train.iloc[test]\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(x_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7374301675977654\n",
      "0.7528089887640449\n",
      "0.7640449438202247\n",
      "0.7808988764044944\n",
      "0.7808988764044944\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(X_train.values, Y_train.values):\n",
    "    x_train, y_train = X_train.iloc[train], Y_train.iloc[train]\n",
    "    x_test, y_test = X_train.iloc[test], Y_train.iloc[test]\n",
    "    my_clf.fit(x_train.values, y_train.values)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(x_test.values), y_true=y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты близки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [10,20,30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7039106145251397 10\n",
      "0.6404494382022472 10\n",
      "0.6797752808988764 10\n",
      "0.7359550561797753 10\n",
      "0.6348314606741573 10\n",
      "0.7486033519553073 20\n",
      "0.7865168539325843 20\n",
      "0.797752808988764 20\n",
      "0.7247191011235955 20\n",
      "0.7528089887640449 20\n",
      "0.776536312849162 30\n",
      "0.7640449438202247 30\n",
      "0.7808988764044944 30\n",
      "0.7528089887640449 30\n",
      "0.7752808988764045 30\n"
     ]
    }
   ],
   "source": [
    "for depth in depths:\n",
    "    my_clf = MyDecisionTreeClassifier(min_samples_split=2, max_depth=depth)\n",
    "    for train, test in gkf.split(X_train.values, Y_train.values):\n",
    "        x_train, y_train = X_train.iloc[train], Y_train.iloc[train]\n",
    "        x_test, y_test = X_train.iloc[test], Y_train.iloc[test]\n",
    "        my_clf.fit(x_train.values, y_train.values)\n",
    "        print(accuracy_score(y_pred=my_clf.predict(x_test.values), y_true=y_test.values), depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше при максимальной глубине 20. Дальше начинается переобучение"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
