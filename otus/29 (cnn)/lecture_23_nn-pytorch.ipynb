{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKvjCssIQCYn"
   },
   "source": [
    "<img src='otus.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch, вычислительные графы.\n",
    "\n",
    "Pytorch - фреймворк для работы с вычислительными графами. Чаще всего Pytorch называют фреймворком для \"глубокого обучения\", но это слегка сужает область его применения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример вычислительного графа для функции $x^2 + xy + (x + y)^2$:\n",
    "\n",
    "<img src='graph.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Как осуществлять операции с тензорами (n-мерные массивы) в Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a_numpy = np.random.randn(100, 1000)   # numpy array\n",
    "a = torch.tensor(a_numpy)   # torch tensor / can be uploaded in GPU memory for faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a ** 2 # element-wise operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669 µs ± 41.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit c = a_numpy.dot(a_numpy.T) # matrix multiplication with itself -- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "886 µs ± 66.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit c = a.mm(a.t())   # matrix multiplication with itself -- pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как рассчитывать градиенты для произвольных (дифференцируемых) функций**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13., 13.],\n",
      "        [13., 13.]])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "# print the gradient of 2x^2 + 5x\n",
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "z = 2 * (x * x) + 5 * x\n",
    "# run the backpropagation\n",
    "z.backward(torch.ones(2, 2))\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как пользоваться интерфейсом модуля torch.nn для быстрого создания НС.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(20, 200),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(200, 1),\n",
    "                      nn.Sigmoid()\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp = torch.randn(3, 20)\n",
    "model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как Pytorch упрощает работу с НС.\n",
    "\n",
    "Мы видели следующие полезные абстракции:\n",
    "\n",
    "1. Модуль torch.nn\n",
    "2. Оптимизаторы torch.optim\n",
    "3. Функции потерь, например torch.nn.BCELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример с MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "FOLDER = 'MNIST_data'\n",
    "\n",
    "if not os.path.exists(FOLDER):\n",
    "    os.mkdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# данные\n",
    "train_set = datasets.MNIST(root=FOLDER, train=True, transform=trans, download=True)\n",
    "test_set = datasets.MNIST(root=FOLDER, train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: MNIST_data\n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# итераторы\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "sample_x, sample_y = next(iter(train_loader))\n",
    "print(sample_x.size())\n",
    "print(sample_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# один скрытый слой, на выходе 10 логитов (по числу классов)\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(784, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10),    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:15<00:00, 119.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Accuracy train: 89.852%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:15<00:00, 122.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; Accuracy train: 95.118%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:19<00:00, 122.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2; Accuracy train: 96.453%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:16<00:00, 116.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3; Accuracy train: 97.223%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:28<00:00, 65.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4; Accuracy train: 97.697%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:23<00:00, 79.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5; Accuracy train: 98.023%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:17<00:00, 108.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6; Accuracy train: 98.305%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:18<00:00, 98.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7; Accuracy train: 98.505%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:15<00:00, 120.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8; Accuracy train: 98.700%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:15<00:00, 121.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9; Accuracy train: 98.888%\n"
     ]
    }
   ],
   "source": [
    "# процесс тренировки; тест напишите для упражнения\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # trainning\n",
    "    av_loss = 0.\n",
    "    correct = 0.\n",
    "    for x, y in tqdm.tqdm(train_loader):\n",
    "        # рассчитываем функцию потерь\n",
    "        x = x.view(BATCH_SIZE, -1)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        # оптимизация параметров\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # подсчет статистики за эпоху\n",
    "        pred = out.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "        av_loss += loss.item()\n",
    "    print('Epoch: {}; Accuracy train: {:.3f}%'.format(epoch, correct / len(train_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Другие оптимизаторы:** https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Пример с MNIST. Сверточная сеть.\n",
    "\n",
    "Идея: обработка участка изображения должна проходить независимо от конкретного расположения участка.\n",
    "\n",
    "<img src='conv.png'>\n",
    "\n",
    "Визуализация применения фильтров на модельном примере: http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "Фильтры: http://cs231n.github.io/understanding-cnn/\n",
    "\n",
    "Популярные архитектуры сверточных сетей: https://github.com/pytorch/vision/tree/master/torchvision/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Прочие примеры DL успехов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Автокодировщик**\n",
    "\n",
    "<img src='AutoEncoder.png'>\n",
    "<img src='autoencoder_schema.jpg'>\n",
    "\n",
    "Идея:  \n",
    "Выделить признаки и закономерности, характеризующие данные. Можно сделать это в пространстве меньшей размерности.  \n",
    "Сделаем так, чтобы сеть обучалась на некоторых данных выдавать те же самые данные. Но с ограничением, слой автокодировщика должен быть меньше (или больше), чем размерность исходных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применение автокодировщиков:\n",
    "* понижение размерности (в нейронной сети нет исходных ограничений в модели, решение более универсальное)\n",
    "* подавление шума (на входе на изображение добавить шум, на выходе ждать исходное изображение)\n",
    "* генерация данных (variational autoencoder, нужно в слой кодировщика добавить ограничение - задать распределение)\n",
    "* другие\n",
    "\n",
    "https://vdumoulin.github.io/morphing_faces/online_demo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PcAI4uX8S6kY"
   },
   "source": [
    "## Литература\n",
    "\n",
    "1. Николенко, Кадурин, Архангельская. Глубокое обучение. Погружение в мир нейронных сетей.\n",
    "2. Aurélien Géron Hands-on Machine Learning with Scikit-Learn and TensorFlow\n",
    "3. Гудфеллоу, Бенджио, Курвилль. Глубокое обучение\n",
    "4. Стэнфордский курс cs231n: http://cs231n.stanford.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "lecture_22_nn.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
