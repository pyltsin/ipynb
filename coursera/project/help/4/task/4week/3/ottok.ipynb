{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ эффективности удержания\n",
    "### Вопрос 1\n",
    "В этом задании вам предлагается проанализировать данные одной из американских телекоммуникационных компаний о пользователях, которые потенциально могут уйти.\n",
    "\n",
    "Измерены следующие признаки:\n",
    "\n",
    " * state — штат США\n",
    " * account_length — длительность использования аккаунта\n",
    " * area_code — деление пользователей на псевдорегионы, использующееся в телекоме\n",
    " * intl_plan — подключена ли у пользователя услуга международного общения\n",
    " * vmail_plan — подключена ли у пользователя услуга голосовых сообщений\n",
    " * vmail_message — количество голосых сообщений, который пользователь отправил / принял\n",
    " * day_calls — сколько пользователь совершил дневных звонков\n",
    " * day_mins — сколько пользователь проговорил минут в течение дня\n",
    " * day_charge — сколько пользователь заплатил за свою дневную активность\n",
    " * eve_calls, eve_mins, eve_charge — аналогичные метрики относительно вечерней активности\n",
    " * night_calls, night_mins, night_charge — аналогичные метрики относительно ночной активности\n",
    " * intl_calls, intl_mins, intl_charge — аналогичные метрики относительно международного общения\n",
    " * custserv_calls — сколько раз пользователь позвонил в службу поддержки\n",
    " * treatment — номер стратегии, которая применялись для удержания абонентов (0, 2 = два разных типа воздействия, 1 = контрольная группа)\n",
    " * mes_estim — оценка интенсивности пользования интернет мессенджерами\n",
    " * churn — результат оттока: перестал ли абонент пользоваться услугами оператора\n",
    "\n",
    "Давайте рассмотрим всех пользователей из контрольной группы (treatment = 1). Для таких пользователей мы хотим проверить гипотезу о том, что штат абонента не влияет на то, перестанет ли абонент пользоваться услугами оператора.\n",
    "\n",
    "Для этого мы воспользуемся критерием хи-квадрат. Постройте таблицы сопряженности между каждой из всех 1275 возможных неупорядоченных пар штатов и значением признака churn. Для каждой такой таблицы 2x2 применить критерий хи-квадрат можно с помощью функции\n",
    "\n",
    "`scipy.stats.chi2_contingency(subtable, correction=False)`\n",
    "\n",
    "Заметьте, что, например, (AZ, HI) и (HI, AZ) — это одна и та же пара. Обязательно выставьте correction=False (о том, что это значит, вы узнаете из следующих вопросов).\n",
    "\n",
    "Сколько достигаемых уровней значимости оказались меньше, чем α=0.05?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('churn_analysis.csv').drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = df.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for state1 in states:\n",
    "    for state2 in states:\n",
    "        if state2 <= state1:\n",
    "            continue\n",
    "        tmp_df = df[(df.treatment == 1) & df.state.isin([state1, state2])]\\\n",
    "            .pivot_table(index = 'state', columns = 'churn', values = 'area_code', aggfunc = 'count').fillna(0)\n",
    "        results[(state1, state2)] = scipy.stats.chi2_contingency(tmp_df, correction=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_corr_df = pd.DataFrame.from_dict(results, orient = 'index')\n",
    "state_corr_df.columns = ['p_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_corr_df[state_corr_df.p_value < 0.05].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 2\n",
    "Какие проблемы Вы видите в построении анализа из первого вопроса? Отметьте все верные утверждения.\n",
    "\n",
    " * Применение критерия xи-квадрат для этих данных не обосновано, потому что не выполняются условия, при которых этот критерий дает правильные результаты.\n",
    "\n",
    " * ~~Поправку на множественную проверку здесь применять нельзя — она используется только для группы критериев, проверяющих равенство средних (типа t-критерия). Критерий xи-квадрат не принадлежит этому семейству, поэтому поправка не нужна.~~\n",
    "\n",
    " * ~~Хи-квадрат используется для того, чтобы сравнить выборку с некоторым воздействием (treatment) и выборку без этого воздействия (control). Мы же в первом задании сравнивали штаты, используя данные только control группы. Для данных только из control группы использование xи-квадрат неправомерно.~~\n",
    "\n",
    " * ~~Анализ нужно было начинать с применения xи-квадрат к таблице сопряженности, в которой присутствовали сразу все возможные штаты. Достигаемой уровень значимости такой проверки = 0.7, что дает нам гарантию, что нет ни одной пары штатов, в которых отличие в соотношениях ушедших и оставшихся клиентов статистически значимо.~~\n",
    "\n",
    " * Интерпретация числа достигаемых уровней значимости, меньших α=0.05, некорректна, поскольку не сделана поправка на множественную проверку гипотез."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Критерий хи-квадрат для таблиц сопряженности может применяться при выполнении следующих условий.\n",
    "Нужно, чтобы выборки были достаточно большими: n ≥ 40. Кроме того, необходимо, чтобы ожидаемое\n",
    " количество элементов в каждой ячейке таблицы было меньше 5 ($\\frac{n_{i+}n_{+j}}{n} < 5$), не более, чем в 20% ячеек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chi2_stats = []\n",
    "for state1 in states:\n",
    "    for state2 in states:\n",
    "        if state2 <= state1:\n",
    "            continue\n",
    "        tmp_df = df[(df.treatment == 1) & df.state.isin([state1, state2])]\\\n",
    "            .pivot_table(index = 'state', columns = 'churn', values = 'area_code', aggfunc = 'count').fillna(0)\n",
    "        n = tmp_df.sum().sum()\n",
    "        exp_cell_values = []\n",
    "        for i in tmp_df.sum().values:\n",
    "            for j in tmp_df.sum(axis = 1).values:\n",
    "                exp_cell_values.append(float(i*j)/n)\n",
    "        chi2_stats.append(\n",
    "            {\n",
    "                'state1': state1,\n",
    "                'state2': state2,\n",
    "                'n': n,\n",
    "                'exp_cell_values': exp_cell_values\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi2_stats_df = pd.DataFrame(chi2_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_stats_df[chi2_stats_df.n < 40].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def small_values(lst):\n",
    "    for i in lst:\n",
    "        if i < 5:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1171, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_stats_df[map(small_values, chi2_stats_df.exp_cell_values)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 3\n",
    "В основе критерия xи-квадрат лежит предположение о том, что если верна нулевая гипотеза, то дискретное биномиальное распределение данных по клеткам в таблице сопряженности может быть аппроксимировано с помощью непрерывного распределения xи-квадрат. Однако точность такой аппроксимации существенно зависит от суммарного количества наблюдений и их распределения в этой таблице (отсюда и ограничения при использовании критерия xи-квадрат).\n",
    "\n",
    "Одним из способов коррекции точности аппроксимации является поправка Йетса на непрерывность. Эта поправка заключается в вычитании константы 0.5 из каждого модуля разности наблюденного Oi и ожидаемого Ei значений, то есть, статистика с такой поправкой выглядит так:\n",
    "$$χ^{2}_{Yates}=\\sum\\limits_{i=1}^{N}\\frac{(|O_{i}−E_{i}|−0.5)^{2}}{E_{i}}$$\n",
    "Такая поправка, как несложно догадаться по формуле, как правило, уменьшает значение статистики χ2, то есть увеличивает достигаемый уровень значимости.\n",
    "\n",
    "Эта поправка обычно используется для таблиц сопряженности размером 2x2 и для небольшого количества наблюдений. Такая поправка, однако, не является серебрянной пулей, и часто критикуется за то, что статистический критерий при ее использовании становится слишком консервативным, то есть часто не отвергает нулевую гипотезу там, где она неверна (совершает ошибку II рода).\n",
    "\n",
    "Полезно знать, что эта поправка часто включена по умолчанию (например, в функции scipy.stats.chi2_contingency) и понимать ее влияние на оценку достигаемого уровня значимости.\n",
    "\n",
    "Проведите те же самые сравнения, что и в вопросе №1, только с включенной коррекцией\n",
    "\n",
    "`scipy.stats.chi2_contingency(subtable, correction=True)`\n",
    "\n",
    "и сравните полученные результаты, отметив все верные варианты.\n",
    "\n",
    " * Количество достигаемых уровней значимости, меньших, чем 0.05, в точности равно нулю. То есть поправка увеличила достигаемые уровни значимости настолько, что больше ни одно из значений достигаемого уровня значимости не попадает в диапазон от 0 до 0.05.\n",
    "\n",
    " * ~~Поправка Йетса на непрерывность всегда увеличивает значение достигаемого уровня значимости, поэтому все получившиеся значения достигаемого уровня значимости строго больше или равны таковым значениям при отсутствии этой поправки.~~\n",
    "\n",
    " * ~~Количество достигаемых уровней значимости, меньших, чем 0.05, почти не изменилось, нельзя сказать, что введенная поправка сильно поменяла достигаемые уровни значимости.~~\n",
    "\n",
    " * Достигаемые уровни значимости на наших данных, полученные с помощью критерия xи-квадрат с поправкой Йетса, в среднем получаются больше, чем соответствующие значения без поправки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_yates = []\n",
    "for state1 in states:\n",
    "    for state2 in states:\n",
    "        if state2 <= state1:\n",
    "            continue\n",
    "        tmp_df = df[(df.treatment == 1) & df.state.isin([state1, state2])]\\\n",
    "            .pivot_table(index = 'state', columns = 'churn', values = 'area_code', aggfunc = 'count').fillna(0)\n",
    "        yates_corr = scipy.stats.chi2_contingency(tmp_df, correction=True)[1]\n",
    "        without_corr = scipy.stats.chi2_contingency(tmp_df, correction=False)[1]\n",
    "        results_yates.append(\n",
    "            {\n",
    "                'state1': state1,\n",
    "                'state2': state2,\n",
    "                'p_values': without_corr,\n",
    "                'p_value_yates': yates_corr\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yates_df = pd.DataFrame(results_yates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_value_yates</th>\n",
       "      <th>p_values</th>\n",
       "      <th>state1</th>\n",
       "      <th>state2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [p_value_yates, p_values, state1, state2]\n",
       "Index: []"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yates_df[yates_df.p_value_yates < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1083, 4)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yates_df[yates_df.p_value_yates >= yates_df.p_values].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 4\n",
    "Что если у нас мало данных, мы не хотим использовать аппроксимацию дискретного распределения непрерывным и использовать сомнительную поправку, предположения критерия xи-квадрат не выполняются, а проверить гипотезу о том, что данные принадлежат одному распределению, нужно ?\n",
    "\n",
    "В таком случае прибегают к так называемому точному критерию Фишера. Этот критерий не использует приближений и в точности вычисляет значение достигаемого уровня значимости используя комбинаторный подход.\n",
    "\n",
    "Пусть у нас есть таблица сопряженности 2x2:\n",
    "\n",
    "Группа 1\tГруппа 2\tΣ\n",
    "Воздействие 1\ta\tb\ta+b\n",
    "Воздействие 2\tc\td\tc+d\n",
    "Σ\ta+c\tb+d\tn=a+b+c+d\n",
    "Тогда вероятность получить именно такие a,b,c,d при фиксированных значениях сумм по строкам и по столбцам) задается выражением\n",
    "\n",
    "p=(a+ba)(c+dc)(na+c)=(a+b)! (c+d)! (a+c)! (b+d)!a!  b!  c!  d!  n!.\n",
    "В числителе этой дроби стоит суммарное количество способов выбрать a и c из a+b и c+d соответственно. А в знаменателе — количество способов выбрать число объектов, равное сумме элементов первого столбца a+c из общего количества рассматриваемых объектов n.\n",
    "\n",
    "Чтобы посчитать достигаемый уровень значимости критерия Фишера, нужно перебрать все возможные значения a,b,c,d, в клетках этой таблицы так, чтобы построковые и постолбцовые суммы не изменились. Для каждого такого набора a,b,c,d нужно вычислить значение pi по формуле выше и просуммировать все такие значения pi, которые меньше или равны p, которое мы вычислили по наблюдаемым значениям a,b,c,d.\n",
    "\n",
    "Понятно, что такой критерий вычислительно неудобен в силу большого количества факториалов в формуле выше. То есть даже при небольших выборках для вычисления значения этого критерия приходится оперировать очень большими числами. Поэтому данным критерием пользуются обычно только для таблиц 2x2, но сам критерий никак не ограничен количеством строк и столбцов, и его можно построить для любой таблицы n×m.\n",
    "\n",
    "Посчитайте для каждой пары штатов, как и в первом задании, достигаемый уровень значимости с помощью точного критерия Фишера и сравните получившиеся значения с двумя другими подходами, описанными выше.\n",
    "\n",
    "Точный критерий Фишера удобно вычислять с помощью функции\n",
    "\n",
    "`scipy.stats.fisher_exact`\n",
    "которая принимает на вход таблицу сопряженности 2x2.\n",
    "\n",
    " * ~~Точный критерий Фишера на наших данных дает значения достигаемого уровня значимости в среднем большие, чем xи-квадрат с поправкой Йетса~~\n",
    "\n",
    " * Точный критерий Фишера на наших данных дает значения достигаемого уровня значимости в среднем меньшие, чем xи-квадрат с поправкой Йетса\n",
    "\n",
    " * Точный критерий Фишера всегда лучше, чем критерий xи-квадрат, потому что не использует аппроксимацию дискретного распределения непрерывным. Однако при увеличении размера выборки его преимущества по сравнению с критерем xи-квадрат уменьшаются, в пределе достигая нуля.\n",
    "\n",
    " * ~~Точный критерий Фишера точно также, как и критерий xи-квадрат, нельзя использовать, если наблюдений < 40 и если ожидаемое значение меньше 5 больше чем в 20% ячейках.~~\n",
    "\n",
    " * ~~Точный критерий Фишера на наших данных дает значения достигаемого уровня значимости в среднем меньшие, чем xи-квадрат без поправки~~\n",
    "\n",
    " * Точный критерий Фишера на наших данных дает значения достигаемого уровня значимости в среднем значительно большие, чем xи-квадрат без поправки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 0.43755120776943679)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.fisher_exact(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_fisher = []\n",
    "for state1 in states:\n",
    "    for state2 in states:\n",
    "        if state2 <= state1:\n",
    "            continue\n",
    "        tmp_df = df[(df.treatment == 1) & df.state.isin([state1, state2])]\\\n",
    "            .pivot_table(index = 'state', columns = 'churn', values = 'area_code', aggfunc = 'count').fillna(0)\n",
    "        yates_corr = scipy.stats.chi2_contingency(tmp_df, correction=True)[1]\n",
    "        without_corr = scipy.stats.chi2_contingency(tmp_df, correction=False)[1]\n",
    "        fisher_exact = scipy.stats.fisher_exact(tmp_df)[1]\n",
    "        results_fisher.append(\n",
    "            {\n",
    "                'state1': state1,\n",
    "                'state2': state2,\n",
    "                'p_values': without_corr,\n",
    "                'p_value_yates': yates_corr,\n",
    "                'p_value_fisher_exact': fisher_exact\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fisher_df = pd.DataFrame(results_fisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 5)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher_df[fisher_df.p_value_fisher_exact > fisher_df.p_value_yates].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1247, 5)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher_df[fisher_df.p_value_fisher_exact > fisher_df.p_values].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 5\n",
    "Давайте попробуем применить полученные знания о разных видах корреляции и ее применимости на практике.\n",
    "\n",
    "Рассмотрим пару признаков day_calls и mes_estim. Посчитайте корреляцию Пирсона между этими признаками на всех данных, ее значимость.\n",
    "\n",
    "Отметьте все верные утверждения.\n",
    "\n",
    " * ~~Корреляция Пирсона имеет положительный знак, и отличие корреляции от нуля на уровне доверия 0.05 не значимо.~~\n",
    "\n",
    " * Корреляция Пирсона имеет отрицательный знак, и отличие корреляции от нуля на уровне доверия 0.05 значимо.\n",
    "\n",
    " * ~~Корреляция Пирсона имеет отрицательный знак, и отличие корреляции от нуля на уровне доверия 0.05 не значимо.~~\n",
    "\n",
    " * ~~Все варианты неверны, потому что значимость корреляции Пирсона можно оценивать только для нормального распределения, как и упоминалось в лекциях.~~\n",
    "\n",
    " * ~~Корреляция Пирсона имеет положительный знак, и отличие корреляции от нуля на уровне доверия 0.05 значимо.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.051794350587572625, 0.0027798836869756707)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(df.day_calls, df.mes_estim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 6\n",
    "Еще раз рассмотрим пару признаков day_calls и mes_estim. Посчитайте корреляцию Спирмена между этими признаками на всех данных, ее значимость.\n",
    "\n",
    "Отметьте все верные утверждения.\n",
    "\n",
    " * Корреляция Спирмена имеет положительный знак, и отличие корреляции от нуля на уровне доверия 0.05 значимо.\n",
    "\n",
    " * ~~Корреляция Спирмена имеет отрицательный знак, и отличие корреляции от нуля на уровне доверия 0.05 значимо.~~\n",
    "\n",
    " * ~~Корреляция Спирмена имеет отрицательный знак, и отличие корреляции от нуля на уровне доверия 0.05 не значимо.~~\n",
    "\n",
    " * ~~Корреляция Спирмена тут неприменима, поскольку речь идет о непрерывных величинах, а корреляция Спирмена применяется к выборочным рангам двух выборок.~~\n",
    "\n",
    " * ~~Корреляция Спирмена имеет положительный знак, и отличие корреляции от нуля на уровне доверия 0.05 не значимо.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.043349880533927444, pvalue=0.012317367189170541)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(df.day_calls, df.mes_estim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 7\n",
    "Как можно интерпретировать полученные значения коэффициентов корреляции и достигаемые уровни значимости при проверки гипотез о равенстве нулю этих коэффициентов?\n",
    "\n",
    " * ~~Не стоит ориентироваться на значение корреляции Спирмена, потому что корреляцию Спирмена можно считать только тогда, когда оба признака дискретные и между значениями можно установить строгий порядок.~~\n",
    "\n",
    " * ~~Предположение нормальности данных двух признаков не выполнено, что хорошо видно на ку-ку графике, поэтому корреляция Пирсона может быть полностью неадекватна.~~\n",
    "\n",
    " * Посчитанные корреляции и их значимости говорят лишь о том, что необходимо взглянуть на данные глазами и попытаться понять, что приводит к таким (противоречивым?) результатам.\n",
    "\n",
    " * ~~Подсчет корреляций не имеет особого смысла, поскольку корреляция ничего не говорит о том, какая на самом деле зависимость имеется между признаками.~~\n",
    " \n",
    "### Вопрос 8\n",
    "Посчитайте значение коэффицента корреляции Крамера между двумя признаками: штатом (state) и оттоком пользователей (churn) для всех пользователей, которые находились в контрольной группе (treatment=1). Что можно сказать о достигаемом уровне значимости при проверке гипотезы о равенство нулю этого коэффициента?\n",
    "\n",
    " * ~~Достигаемый уровень значимости < 0.05, то есть, отличие от нуля значения коэффицента Крамера значимо.~~\n",
    "\n",
    " * ~~Достигаемый уровень значимости > 0.05, то есть, отличие от нуля значения коэффицента Крамера незначимо.~~\n",
    "\n",
    " * Для вычисления коэффициента Крамера используется значение статистики xи-квадрат, на которую мы не можем положиться применительно к нашим данным.\n",
    "\n",
    " * ~~Коэффициент корреляции Крамера не может быть использован для сравнения связи этих двух признаков, потому что он используется для таблиц сопряженности, где каждая из размерностей больше двух. Если хотя бы одна из размерностей равна 2, то нужно использовать коэффициент корреляции Мэтьюса.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cramers_stat(confusion_matrix):\n",
    "    chi2 = scipy.stats.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    return np.sqrt(chi2 / (n*(min(confusion_matrix.shape)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmp_df = df[df.treatment == 1].pivot_table(index = 'state', columns = 'churn', \n",
    "                                  values = 'area_code', aggfunc = 'count').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20039321502033319"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cramers_stat(cmp_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70975900427784411"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.chi2_contingency(cmp_df)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 9\n",
    "Вы прослушали большой курс и к текущему моменту обладете достаточными знаниями, чтобы попытаться самостоятельно выбрать нужный метод / инструмент / статистический критерий и сделать правильное заключение.\n",
    "\n",
    "В этой части задания вам нужно будет самостоятельно решить, с помощью каких методов можно провести анализ эффективности удержания (churn) с помощью раличных методов (treatment = 0, treatment = 2) относительно контрольной группы пользователей (treatment = 1).\n",
    "\n",
    "Что можно сказать об этих двух методах (treatment = 0, treatment = 2)? Одинаковы ли они с точки зрения эффективности? Каким бы методом вы бы посоветовали воспользоваться компании?\n",
    "\n",
    "Не забудьте про поправку на множественную проверку! И не пользуйтесь односторонними альтернативами, поскольку вы не знаете, к каким действительно последствиям приводят тестируемые методы (treatment = 0, treatment = 2) !\n",
    "\n",
    " * ~~Ни один из методов не показал значительного улучшения относительно других, о чем говорит групповой статистический критерий.~~\n",
    "\n",
    " * ~~treatment = 0 статистически значимо отличается от контрольной группы treatment = 1~~\n",
    "\n",
    " * treatment = 2 статистически значимо отличается от контрольной группы treatment = 1\n",
    "\n",
    " * ~~В дальнейшем телеком компании рекомендуется использовать и treatment = 0, и treatment = 2 для наибольшей эффективности удержения абонентов.~~\n",
    "\n",
    " * Отличие между treatment = 0 и treatment = 2 относительно влияния на уровень churn статистически незначимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportions_diff(sample1, sample2):\n",
    "    n1 = len(sample1)\n",
    "    n2 = len(sample2)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / n1\n",
    "    p2 = float(sum(sample2)) / n2 \n",
    "    return p1, p2\n",
    "\n",
    "def proportions_diff_z_stat_ind(sample1, sample2):\n",
    "    n1 = len(sample1)\n",
    "    n2 = len(sample2)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / n1\n",
    "    p2 = float(sum(sample2)) / n2 \n",
    "    #print p1, p2\n",
    "    P = float(p1*n1 + p2*n2) / (n1 + n2)\n",
    "    \n",
    "    return (p1 - p2) / np.sqrt(P * (1 - P) * (1. / n1 + 1. / n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportions_diff_z_test(z_stat, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return scipy.stats.norm.cdf(z_stat)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return 1 - scipy.stats.norm.cdf(z_stat)\n",
    "    \n",
    "def proportions_diff_confint_ind(sample1, sample2, alpha = 0.05):    \n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / len(sample1)\n",
    "    p2 = float(sum(sample2)) / len(sample2)\n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    \n",
    "    return (left_boundary, right_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['churn_value'] = map(lambda x: 1 if x == 'True.' else 0, df.churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treatment_0 = df[df.treatment == 0].churn_value\n",
    "treatment_2 = df[df.treatment == 2].churn_value\n",
    "treatment_0_2 = df[df.treatment.isin([2,0])].churn_value\n",
    "control = df[df.treatment == 1].churn_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparison = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = {\n",
    "    'treatment0_vs_control': (treatment_0, control),\n",
    "    'treatment2_vs_control': (treatment_2, control),\n",
    "    'treatment02_vs_control': (treatment_0_2, control),\n",
    "    'treatment0_vs_treatment2': (treatment_0, treatment_2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyp_results = []\n",
    "for name in hypothesis:\n",
    "    sample1, sample2 = hypothesis[name]\n",
    "    churn1, churn2 = proportions_diff(sample1, sample2)\n",
    "    p_value = proportions_diff_z_test(proportions_diff_z_stat_ind(sample1, sample2))\n",
    "    left_boundary, right_boundary = proportions_diff_confint_ind(sample1, sample2)\n",
    "    hyp_results.append(\n",
    "        {\n",
    "            'hypothesis': name,\n",
    "            'churn1': churn1,\n",
    "            'churn2': churn2,\n",
    "            'p_value': p_value,\n",
    "            'left_boundary': left_boundary,\n",
    "            'right_boundary': right_boundary\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyp_df = pd.DataFrame(hyp_results).set_index('hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn1</th>\n",
       "      <th>churn2</th>\n",
       "      <th>left_boundary</th>\n",
       "      <th>p_value</th>\n",
       "      <th>right_boundary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypothesis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>treatment0_vs_treatment2</th>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.125113</td>\n",
       "      <td>-0.007821</td>\n",
       "      <td>0.156425</td>\n",
       "      <td>0.048856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment02_vs_control</th>\n",
       "      <td>0.135510</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.054681</td>\n",
       "      <td>0.027660</td>\n",
       "      <td>-0.002467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment0_vs_control</th>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.048489</td>\n",
       "      <td>0.228331</td>\n",
       "      <td>0.011583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment2_vs_control</th>\n",
       "      <td>0.125113</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.068322</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>-0.009619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            churn1    churn2  left_boundary   p_value  \\\n",
       "hypothesis                                                              \n",
       "treatment0_vs_treatment2  0.145631  0.125113      -0.007821  0.156425   \n",
       "treatment02_vs_control    0.135510  0.164084      -0.054681  0.027660   \n",
       "treatment0_vs_control     0.145631  0.164084      -0.048489  0.228331   \n",
       "treatment2_vs_control     0.125113  0.164084      -0.068322  0.009348   \n",
       "\n",
       "                          right_boundary  \n",
       "hypothesis                                \n",
       "treatment0_vs_treatment2        0.048856  \n",
       "treatment02_vs_control         -0.002467  \n",
       "treatment0_vs_control           0.011583  \n",
       "treatment2_vs_control          -0.009619  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reject, p_corrected, a1, a2 = multipletests(hyp_df.p_value, \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'holm')\n",
    "hyp_df['p_value_holm'] = p_corrected\n",
    "hyp_df['reject_holm'] = reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reject, p_corrected, a1, a2 = multipletests(hyp_df.p_value, \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'fdr_bh')\n",
    "hyp_df['p_value_bh'] = p_corrected\n",
    "hyp_df['reject_bh'] = reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn1</th>\n",
       "      <th>churn2</th>\n",
       "      <th>left_boundary</th>\n",
       "      <th>p_value</th>\n",
       "      <th>right_boundary</th>\n",
       "      <th>p_value_holm</th>\n",
       "      <th>reject_holm</th>\n",
       "      <th>p_value_bh</th>\n",
       "      <th>reject_bh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypothesis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>treatment0_vs_treatment2</th>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.125113</td>\n",
       "      <td>-0.007821</td>\n",
       "      <td>0.156425</td>\n",
       "      <td>0.048856</td>\n",
       "      <td>0.312849</td>\n",
       "      <td>False</td>\n",
       "      <td>0.208566</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment02_vs_control</th>\n",
       "      <td>0.135510</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.054681</td>\n",
       "      <td>0.027660</td>\n",
       "      <td>-0.002467</td>\n",
       "      <td>0.082980</td>\n",
       "      <td>False</td>\n",
       "      <td>0.055320</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment0_vs_control</th>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.048489</td>\n",
       "      <td>0.228331</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.312849</td>\n",
       "      <td>False</td>\n",
       "      <td>0.228331</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment2_vs_control</th>\n",
       "      <td>0.125113</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.068322</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>-0.009619</td>\n",
       "      <td>0.037392</td>\n",
       "      <td>True</td>\n",
       "      <td>0.037392</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            churn1    churn2  left_boundary   p_value  \\\n",
       "hypothesis                                                              \n",
       "treatment0_vs_treatment2  0.145631  0.125113      -0.007821  0.156425   \n",
       "treatment02_vs_control    0.135510  0.164084      -0.054681  0.027660   \n",
       "treatment0_vs_control     0.145631  0.164084      -0.048489  0.228331   \n",
       "treatment2_vs_control     0.125113  0.164084      -0.068322  0.009348   \n",
       "\n",
       "                          right_boundary  p_value_holm reject_holm  \\\n",
       "hypothesis                                                           \n",
       "treatment0_vs_treatment2        0.048856      0.312849       False   \n",
       "treatment02_vs_control         -0.002467      0.082980       False   \n",
       "treatment0_vs_control           0.011583      0.312849       False   \n",
       "treatment2_vs_control          -0.009619      0.037392        True   \n",
       "\n",
       "                          p_value_bh reject_bh  \n",
       "hypothesis                                      \n",
       "treatment0_vs_treatment2    0.208566     False  \n",
       "treatment02_vs_control      0.055320     False  \n",
       "treatment0_vs_control       0.228331     False  \n",
       "treatment2_vs_control       0.037392      True  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
=======
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
>>>>>>> a15b9d7091eb48167953e419ebdfab6a261ee4ff
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
